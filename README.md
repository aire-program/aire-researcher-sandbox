# AIRE Researcher Sandbox (Synthetic Data)

This repository provides a notebook-first, synthetic-data mirror of the internal AIRE research environment used at Michigan State University. It is designed for reliable local and Colab execution, with pipelines, schemas, and tests that match the internal layout while keeping all data non-sensitive.

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](docs/colab_index.md)

## What / Why / How
- **What**: A notebook-first sandbox with synthetic data, pipelines, and tests that mirror internal AIRE research workflows.
- **Why**: Ensures reproducible local and Colab execution for experimentation, schema validation, and governance documentation without exposing operational records.
- **How**: Generate synthetic data, run the notebooks or pipelines end-to-end, and validate outputs against JSON Schemas and tests.

## Purpose and Context
- **Notebook and pipeline focus**: All workflows run in Jupyter/Colab with matching Python pipelines for reuse.
- **Operational coverage**: Tracks adoption-like signals, workshop engagement, confidence deltas, and usage patterns using synthetic data shaped like the internal system.
- **Reproducible analytics**: Scripts and tests keep data generation, schemas, and retrieval utilities consistent across environments.
- **Governance alignment**: Responsible-use templates and schema checks accompany every workflow.

## Data Model (synthetic mirror)
- **Adoption-style signals**: Composite indicators derived from usage intensity, feature coverage, and recency signals in `data/sample_tabular/metrics_sample.csv`.
- **Workshop metrics**: Participation counts, completion rates, and engagement notes represented by `data/sample_texts/notes_sample.csv` and `data/sample_tabular/experiments_sample.csv`.
- **Confidence deltas**: Pre/post confidence shifts encoded in the synthetic metrics and notes.
- **Usage patterns**: Article abstracts and summaries in `data/sample_texts/articles_sample.csv` simulate resource interactions for retrieval and clustering exercises.
- All data is generated by `scripts/generate_synthetic_data.py` and conforms to schemas in `data/schemas/`, matching the internal structure while remaining non-sensitive.

## Quickstart
- **Install**: `pip install -r requirements.txt`
- **(Optional) Install test runner**: `pip install pytest`
- **Generate synthetic data**: `python scripts/generate_synthetic_data.py`
- **Validate**: `pytest` (schema, API client, and retrieval tests)
- **Explore**: open notebooks via the Colab badge above or in `docs/colab_index.md`
- **Optional**: environment check with `python scripts/validate_environment.py`

## Components
- **Notebooks**: Calculation walkthroughs for adoption-style indicators, workshop outcomes, confidence deltas, and usage exploration.
- **Pipelines**: Reusable Python modules for text processing, embeddings, retrieval, and tabular feature creation.
- **Synthetic datasets + schemas**: Programmatically generated CSVs with explicit JSON Schemas that mirror internal structures.
- **Governance toolkit**: Templates for responsible use, provenance, model cards, and release checklists to accompany analytics outputs.
- **CI and tests**: Pytest suite for schemas, API clients, and retrieval indexing to keep the public mirror reproducible.

## Available Workflows
- **Adoption and usage**: `notebooks/tabular_basics.ipynb` and `notebooks/tabular_modeling.ipynb` illustrate how adoption-style aggregates are derived.
- **Workshop engagement**: `notebooks/text_cleaning.ipynb` and `notebooks/text_classification.ipynb` surface thematic signals from workshop notes and abstracts.
- **Retrieval-assisted insights**: `notebooks/rag_build_index.ipynb` and `notebooks/rag_query.ipynb` demonstrate retrieval over synthetic resources.
- **Governance documentation**: Adapt `governance/data_provenance_template.md` and `governance/model_card_template.md` alongside each workflow to record assumptions and limitations.

## Relationship to AIRE Program and Applied AI Literacy Hub
The sandbox mirrors the internal research workflows used by the AIRE Program. While the Applied AI Literacy Hub focuses on pedagogy and training content, this sandbox provides reproducible calculations, pipelines, and a transparent synthetic-data mirror for external review.

## Synthetic Data and Safety
All datasets are generated via `scripts/generate_synthetic_data.py` and contain no real records. JSON Schemas in `data/schemas/` document every column, and tests enforce conformance. The synthetic mirror preserves logic and structure without exposing operational or sensitive information.

## Running Locally (How-to)
1. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```
2. **Generate synthetic data**:
   ```bash
   python scripts/generate_synthetic_data.py
   ```
3. **Run tests**:
   ```bash
   pytest
   ```
4. **Run notebooks or pipelines**:
   - Open notebooks locally (`jupyter notebook`) or via the Colab links in `docs/colab_index.md`.
   - Run CLI examples such as `python scripts/run_pipeline_example.py`.

## CI and Testing
- `.github/workflows/ci.yml` runs linting, synthetic data generation, tests, notebook execution, and structural checks.
- `.github/workflows/smoke-tests.yml` regenerates data and verifies required files on targeted changes.

## Colab Access
Use the Colab launch buttons in `docs/colab_index.md` for one-click execution in Google Colab. Each notebook includes a setup cell to install dependencies when running in Colab.

## Glossary (for quick orientation)
- **Adoption index**: Composite signal combining feature coverage, recency, and usage intensity to summarize platform uptake (synthetic in this mirror).
- **Workshop metrics**: Participation counts, completion, and qualitative notes describing training engagement.
- **Confidence delta**: Change between pre- and post-event confidence signals, aggregated for reporting.
- **Usage patterns**: Behavioral summaries and representative content interactions used to contextualize adoption and training outcomes.
- **TF-IDF**: Term frequencyâ€“inverse document frequency; turns text into weighted numeric vectors for similarity and clustering in the synthetic mirror.
- **RAG**: Retrieval-augmented generation; pairs a retriever (TF-IDF here) with a responder to ground outputs in source documents.
- **Governance templates**: Documents in `governance/` to record provenance, intended use, model details, and release checks before sharing analytics or prototypes.

## Tools and Stack
- **Colab/Jupyter**: run notebooks interactively; the first cell installs dependencies automatically in Colab.
- **pandas/numpy**: inspect and transform synthetic text and tabular data.
- **scikit-learn**: build TF-IDF vectors, cluster documents, and compute similarities.
- **jsonschema/pytest**: validate data integrity and keep workflows reproducible.
- **requests**: demonstrate simple REST and embeddings client patterns.
