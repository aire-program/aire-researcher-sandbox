{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "if \"google.colab\" in sys.modules:\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"pandas\", \"numpy\", \"scikit-learn\", \"requests\", \"pydantic\", \"jsonschema\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536bbcf3",
   "metadata": {},
   "source": [
    "# Build a TF-IDF Retrieval Index\n",
    "\n",
    "**What this notebook does:** Constructs and saves a TF-IDF index over synthetic article abstracts for later querying.\n",
    "\n",
    "**Why it matters:** Retrieval-augmented workflows rely on consistent indexing; practicing locally ensures repeatability before touching sensitive data.\n",
    "\n",
    "**How to use it:**\n",
    "1. Generate data, then run locally or in Colab.\n",
    "2. Execute cells to fit the vectorizer and persist `vector_index.pkl`.\n",
    "3. Tweak vectorizer parameters to match your domain.\n",
    "\n",
    "**Expected outcome:** A saved index file with document IDs and TF-IDF matrix ready for querying or evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfdc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_data_dir() -> Path:\n",
    "    candidates = [Path.cwd() / \"data\", Path.cwd().parent / \"data\", Path.cwd().parent.parent / \"data\"]\n",
    "    for candidate in candidates:\n",
    "        if (candidate / \"sample_texts\" / \"articles_sample.csv\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"data directory not found. Run scripts/generate_synthetic_data.py.\")\n",
    "\n",
    "DATA_DIR = find_data_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "articles = pd.read_csv(DATA_DIR / \"sample_texts\" / \"articles_sample.csv\")\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix = vectorizer.fit_transform(articles[\"abstract\"].fillna(\"\"))\n",
    "\n",
    "index_payload = {\n",
    "    \"vectorizer\": vectorizer,\n",
    "    \"tfidf_matrix\": tfidf_matrix,\n",
    "    \"article_ids\": articles[\"article_id\"].tolist(),\n",
    "}\n",
    "index_path = DATA_DIR / \"vector_index.pkl\"\n",
    "with open(index_path, \"wb\") as handle:\n",
    "    pickle.dump(index_payload, handle)\n",
    "print(f\"Index saved to {index_path} with shape {tfidf_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce7329a",
   "metadata": {},
   "source": [
    "### If you get stuck / What to try next\n",
    "\n",
    "If you get stuck: confirm data generation, rerun installs, and check that TF-IDF parameters match available RAM. What to try next: query the index in pipelines/rag/rag_query.ipynb and compare queries in pipelines/rag/rag_evaluation.ipynb."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
