{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877f2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "if \"google.colab\" in sys.modules:\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"pandas\", \"numpy\", \"scikit-learn\", \"requests\", \"pydantic\", \"jsonschema\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8484c0",
   "metadata": {},
   "source": [
    "# Semantic-Style Similarity Demo\n",
    "\n",
    "**What:** Use TF-IDF cosine similarity as a stand-in for embedding-based search over synthetic abstracts.\n",
    "\n",
    "**Why:** It shows how to rank documents without remote embedding services, ideal for quick literature scans.\n",
    "\n",
    "**How:** Run the install cell if needed, confirm data presence, then execute cells. Cosine similarity is a simple score of how close two text vectors are.\n",
    "\n",
    "**You will learn:** How preprocessing affects similarity and how to read nearest-neighbor results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5ad7e",
   "metadata": {},
   "source": [
    "### Success criteria\n",
    "- You computed similarity across abstracts.\n",
    "- You inspected the closest pairs.\n",
    "- You understand how preprocessing affects similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfdc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_data_dir() -> Path:\n",
    "    candidates = [Path.cwd() / \"data\", Path.cwd().parent / \"data\", Path.cwd().parent.parent / \"data\"]\n",
    "    for candidate in candidates:\n",
    "        if (candidate / \"sample_texts\" / \"articles_sample.csv\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"data directory not found. Run scripts/generate_synthetic_data.py.\")\n",
    "\n",
    "DATA_DIR = find_data_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39623f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "articles = pd.read_csv(DATA_DIR / \"sample_texts\" / \"articles_sample.csv\")\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "embeddings = vectorizer.fit_transform(articles[\"abstract\"].fillna(\"\"))\n",
    "\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Show the most similar pair (excluding diagonal)\n",
    "import numpy as np\n",
    "np.fill_diagonal(similarity_matrix, 0)\n",
    "max_idx = similarity_matrix.argmax()\n",
    "row, col = divmod(max_idx, similarity_matrix.shape[0])\n",
    "\n",
    "print(\"Most similar pair:\")\n",
    "print(articles.iloc[row][\"title\"])\n",
    "print(articles.iloc[col][\"title\"])\n",
    "print(\"Similarity score\", similarity_matrix[row, col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2645efa",
   "metadata": {},
   "source": [
    "### If you get stuck / What to try next\n",
    "\n",
    "If you get stuck: rerun installs and confirm data presence. What to try next: adjust preprocessing or move to retrieval notebooks to test ranking changes."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
