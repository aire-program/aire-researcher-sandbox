{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "if \"google.colab\" in sys.modules:\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"pandas\", \"numpy\", \"scikit-learn\", \"requests\", \"pydantic\", \"jsonschema\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5a97d",
   "metadata": {},
   "source": [
    "# Clean Synthetic Experiment Records\n",
    "\n",
    "**What:** Load experiment data, parse timestamps, and check for missing or out-of-range values.\n",
    "\n",
    "**Why:** Basic validation catches issues before modeling and keeps results trustworthy.\n",
    "\n",
    "**How:** Install dependencies in Colab via the first cell, confirm data generation, then run cells in order. Sanity checks here mean looking for nulls, bad ranges, or malformed timestamps.\n",
    "\n",
    "**You will learn:** How to inspect tabular research data quickly and decide whether more cleaning is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ef4ff6",
   "metadata": {},
   "source": [
    "### Success criteria\n",
    "- You loaded experiment records.\n",
    "- You parsed timestamps and checked ranges.\n",
    "- You flagged or confirmed data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfdc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_data_dir() -> Path:\n",
    "    candidates = [Path.cwd() / \"data\", Path.cwd().parent / \"data\", Path.cwd().parent.parent / \"data\"]\n",
    "    for candidate in candidates:\n",
    "        if (candidate / \"sample_texts\" / \"articles_sample.csv\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"data directory not found. Run scripts/generate_synthetic_data.py.\")\n",
    "\n",
    "DATA_DIR = find_data_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2ecf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "experiments = pd.read_csv(DATA_DIR / \"sample_tabular\" / \"experiments_sample.csv\")\n",
    "experiments[\"timestamp\"] = pd.to_datetime(experiments[\"timestamp\"])\n",
    "\n",
    "print(\"Dataset shape\", experiments.shape)\n",
    "print(\"Missing values\", experiments.isna().sum())\n",
    "experiments.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8e9fd",
   "metadata": {},
   "source": [
    "## Basic range checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6552bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_out_of_range = (~experiments[\"metric_value\"].between(0, 100)).sum()\n",
    "print(f\"Records outside expected metric range: {metric_out_of_range}\")\n",
    "experiments.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc588b16",
   "metadata": {},
   "source": [
    "### If you get stuck / What to try next\n",
    "\n",
    "If you get stuck: ensure timestamps parse by rerunning the cleaning cell; confirm data generation. What to try next: create features in pipelines/tabular/feature_engineering.ipynb and visualize them in the Streamlit Tabular Workflows page."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
