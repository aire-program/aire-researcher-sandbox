{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958fe92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "if \"google.colab\" in sys.modules:\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"pandas\", \"numpy\", \"scikit-learn\", \"requests\", \"pydantic\", \"jsonschema\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6922743d",
   "metadata": {},
   "source": [
    "### Success criteria\n",
    "- You computed normalized metrics.\n",
    "- You derived categorical/time features.\n",
    "- You prepared a feature-rich table for downstream use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0163d3a",
   "metadata": {},
   "source": [
    "# Engineer Features from Experiments\n",
    "\n",
    "**What this notebook does:** Derives simple normalized metrics, categorical indicators, and time-based features from synthetic experiment data.\n",
    "\n",
    "**Why it matters:** Feature engineering turns raw measures into model-ready signals and is a repeatable pattern across research studies.\n",
    "\n",
    "**How to use it:**\n",
    "1. Run after cleaning notebook (or regenerate data).\n",
    "2. Execute cells to compute normalized metrics, day-of-week, and treatment flags; extend with your own features.\n",
    "\n",
    "**Expected outcome:** An augmented dataset with additional columns you can feed into baseline models or visual analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfdc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_data_dir() -> Path:\n",
    "    candidates = [Path.cwd() / \"data\", Path.cwd().parent / \"data\", Path.cwd().parent.parent / \"data\"]\n",
    "    for candidate in candidates:\n",
    "        if (candidate / \"sample_texts\" / \"articles_sample.csv\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"data directory not found. Run scripts/generate_synthetic_data.py.\")\n",
    "\n",
    "DATA_DIR = find_data_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa03ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "experiments = pd.read_csv(DATA_DIR / \"sample_tabular\" / \"experiments_sample.csv\")\n",
    "experiments[\"timestamp\"] = pd.to_datetime(experiments[\"timestamp\"])\n",
    "\n",
    "experiments[\"metric_normalized\"] = (experiments[\"metric_value\"] - experiments[\"metric_value\"].mean()) / experiments[\"metric_value\"].std()\n",
    "experiments[\"day_of_week\"] = experiments[\"timestamp\"].dt.day_name()\n",
    "experiments[\"is_treatment\"] = experiments[\"condition\"].str.contains(\"treatment\")\n",
    "experiments[[\"experiment_id\", \"condition\", \"metric_value\", \"metric_normalized\", \"day_of_week\", \"is_treatment\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e33b5e",
   "metadata": {},
   "source": [
    "### If you get stuck / What to try next\n",
    "\n",
    "If you get stuck: verify the cleaning notebook ran and that dependencies installed. What to try next: prototype simple models or export features to the Streamlit app for quick views."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
