{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5285bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIRE Micro Tutor Identity Cell\n",
    "import datetime as dt\n",
    "learner_id = input('Enter your learner ID (email or handle): ').strip()\n",
    "learner_role = input('Enter your learner role (e.g., researcher, educator): ').strip()\n",
    "resource_id = 'notebook:rest_api_example'\n",
    "session_id = f\"{learner_id}-{dt.datetime.utcnow().isoformat()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cdaa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIRE Micro Tutor Imports\n",
    "from prompt_tutor import evaluate_prompt\n",
    "from aire_telemetry import log_event\n",
    "from resources_map import RESOURCE_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561becad",
   "metadata": {
    "id": "cell-b786f044"
   },
   "outputs": [],
   "source": [
    "import sys, subprocess, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Colab Setup\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Running in Google Colab. Installing dependencies...\")\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"pandas\", \"numpy\", \"scikit-learn\", \"requests\", \"pydantic\", \"jsonschema\", \"plotly\", \"tqdm\"])\n",
    "    \n",
    "    # Check for data\n",
    "    if not (Path.cwd() / \"data\").exists():\n",
    "        print(\"Data directory not found. Cloning repository...\")\n",
    "        subprocess.run([\"git\", \"clone\", \"https://github.com/aire-program/aire-researcher-sandbox.git\", \"_repo\"])\n",
    "        \n",
    "        # Move data and scripts to current directory\n",
    "        if (Path(\"_repo/data\").exists()):\n",
    "            print(\"Moving data and scripts...\")\n",
    "            subprocess.run([\"mv\", \"_repo/data\", \".\"])\n",
    "            subprocess.run([\"mv\", \"_repo/scripts\", \".\"])\n",
    "            subprocess.run([\"rm\", \"-rf\", \"_repo\"])\n",
    "        else:\n",
    "            print(\"Warning: Data not found in cloned repo.\")\n",
    "    else:\n",
    "        print(\"Data directory found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6924a",
   "metadata": {
    "id": "cell-b749cfae"
   },
   "source": [
    "# REST API Client Example\n",
    "\n",
    "**What**: Interact with a synthetic REST API to manage research data.\n",
    "\n",
    "**Why**: Modern research often involves interacting with remote data services. Understanding REST patterns is a key skill.\n",
    "\n",
    "**How**:\n",
    "1. **Initialize the client**.\n",
    "2. **Make GET requests** to retrieve data.\n",
    "3. **Make POST requests** to submit data.\n",
    "\n",
    "**Key Concept**: **REST** (Representational State Transfer) is a standard architectural style for creating web services.\n",
    "\n",
    "By the end of this notebook, you will have completed the listed steps and produced the outputs described in the success criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c20f082",
   "metadata": {
    "id": "cell-88302ed9"
   },
   "source": [
    "### Success criteria\n",
    "- You called the synthetic clientâ€™s health, GET, and POST helpers.\n",
    "- You saw JSON responses.\n",
    "- You traced request parameters for future adaptation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad54a9",
   "metadata": {
    "id": "health-setup"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd()\n",
    "for candidate in [repo_root, repo_root.parent, repo_root.parent.parent]:\n",
    "    if (candidate / \"api\" / \"python\" / \"client_rest_api.py\").exists():\n",
    "        sys.path.append(str(candidate))\n",
    "        break\n",
    "\n",
    "from api.python.client_rest_api import ResearchAPIClient\n",
    "\n",
    "\n",
    "class DummyResponse:\n",
    "    def __init__(self, payload):\n",
    "        self._payload = payload\n",
    "\n",
    "    def raise_for_status(self):\n",
    "        return None\n",
    "\n",
    "    def json(self):\n",
    "        return self._payload\n",
    "\n",
    "\n",
    "class DummySession:\n",
    "    def __init__(self):\n",
    "        self.last_request = None\n",
    "\n",
    "    def request(self, method: str, url: str, timeout: int = 5, **kwargs):\n",
    "        self.last_request = {\"method\": method, \"url\": url, \"kwargs\": kwargs, \"timeout\": timeout}\n",
    "        if url.endswith(\"/projects\"):\n",
    "            payload = {\"projects\": [\n",
    "                {\"project_id\": \"PRJ-001\", \"title\": \"Synthetic Study A\"},\n",
    "                {\"project_id\": \"PRJ-002\", \"title\": \"Synthetic Study B\"},\n",
    "            ]}\n",
    "        elif url.endswith(\"/datasets\"):\n",
    "            dataset_id = (kwargs.get(\"json\") or {}).get(\"dataset_id\", \"UNKNOWN\")\n",
    "            payload = {\"dataset_id\": dataset_id, \"schema_version\": \"v1\", \"status\": \"described\"}\n",
    "        else:\n",
    "            payload = {\"status\": \"ok\", \"method\": method, \"url\": url}\n",
    "        return DummyResponse(payload)\n",
    "\n",
    "\n",
    "client = ResearchAPIClient(base_url=\"https://example.test\", session=DummySession())\n",
    "health = client.health()\n",
    "health\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b097c63f",
   "metadata": {
    "id": "projects-md"
   },
   "source": [
    "## Retrieve synthetic projects\n",
    "\n",
    "Projects are returned from the dummy session without real network calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0bbf6",
   "metadata": {
    "id": "projects"
   },
   "outputs": [],
   "source": [
    "projects = client.get_json(\"/projects\", params={\"limit\": 3})\n",
    "projects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7a66cb",
   "metadata": {
    "id": "dataset-md"
   },
   "source": [
    "## Fetch dataset metadata\n",
    "\n",
    "POST helpers echo synthetic dataset metadata using the dummy session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa03515",
   "metadata": {
    "id": "dataset"
   },
   "outputs": [],
   "source": [
    "dataset = client.post_json(\"/datasets\", payload={\"dataset_id\": \"DATASET-001\", \"action\": \"describe\"})\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13df7f63",
   "metadata": {
    "id": "cell-90bb349e"
   },
   "source": [
    "### If you get stuck / What to try next\n",
    "\n",
    "If you get stuck: rerun dependency install and ensure repo root is on sys.path (handled in the notebook). What to try next: adapt payloads to your own endpoints or explore embeddings in api/notebooks/embeddings_api_example.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73084e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIRE Micro Tutor Prompt + Feedback Cell\n",
    "from aire_llm_client import chat_completion\n",
    "\n",
    "def call_llm(prompt_text: str) -> str:\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': 'You are an AI helper responding concisely.'},\n",
    "        {'role': 'user', 'content': prompt_text},\n",
    "    ]\n",
    "    return chat_completion(messages)\n",
    "\n",
    "prompt_text = input('Enter the prompt you want to test: ').strip()\n",
    "ai_response = call_llm(prompt_text)\n",
    "evaluation = evaluate_prompt(prompt_text, learner_role)\n",
    "\n",
    "clarity = evaluation.get('clarity_score')\n",
    "context = evaluation.get('context_score')\n",
    "constraints = evaluation.get('constraints_score')\n",
    "evaluation_score = evaluation.get('evaluation_score')\n",
    "primary_weakness = evaluation.get('primary_weakness', '')\n",
    "recommended_resource_id = RESOURCE_MAP.get(primary_weakness) or RESOURCE_MAP.get('evaluation')\n",
    "\n",
    "log_event(\n",
    "    event_name='micro_tutor_evaluation',\n",
    "    user_id=learner_id or session_id,\n",
    "    metadata={\n",
    "        'resource_id': resource_id,\n",
    "        'learner_role': learner_role,\n",
    "        'clarity': clarity,\n",
    "        'context': context,\n",
    "        'constraints': constraints,\n",
    "        'evaluation_score': evaluation_score,\n",
    "        'primary_weakness': primary_weakness,\n",
    "    },\n",
    ")\n",
    "\n",
    "print('\\n--- AI Response ---')\n",
    "print(ai_response)\n",
    "print('\\n--- Feedback ---')\n",
    "print(evaluation.get('summary', 'No summary provided.'))\n",
    "print('Primary weakness:', primary_weakness or 'n/a')\n",
    "print('Strengths:', ', '.join(evaluation.get('strengths', [])) or 'n/a')\n",
    "print('Suggestions:', ', '.join(evaluation.get('suggestions', [])) or 'n/a')\n",
    "print('\\nRecommended resource:', recommended_resource_id or 'n/a')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
