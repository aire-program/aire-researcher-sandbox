{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIRE Micro Tutor Identity Cell\n",
    "import datetime as dt\n",
    "learner_id = input('Enter your learner ID (email or handle): ').strip()\n",
    "learner_role = input('Enter your learner role (e.g., researcher, educator): ').strip()\n",
    "resource_id = 'notebook:embeddings_basics'\n",
    "session_id = f\"{learner_id}-{dt.datetime.utcnow().isoformat()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef2dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIRE Micro Tutor Imports\n",
    "from prompt_tutor import evaluate_prompt\n",
    "from aire_telemetry import log_event\n",
    "from resources_map import RESOURCE_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef659605",
   "metadata": {
    "id": "cell-9dff2bf6"
   },
   "outputs": [],
   "source": [
    "import sys, subprocess, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Colab Setup\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Running in Google Colab. Installing dependencies...\")\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"pandas\", \"numpy\", \"scikit-learn\", \"requests\", \"pydantic\", \"jsonschema\", \"plotly\", \"tqdm\"])\n",
    "    \n",
    "    # Check for data\n",
    "    if not (Path.cwd() / \"data\").exists():\n",
    "        print(\"Data directory not found. Cloning repository...\")\n",
    "        subprocess.run([\"git\", \"clone\", \"https://github.com/aire-program/aire-researcher-sandbox.git\", \"_repo\"])\n",
    "        \n",
    "        # Move data and scripts to current directory\n",
    "        if (Path(\"_repo/data\").exists()):\n",
    "            print(\"Moving data and scripts...\")\n",
    "            subprocess.run([\"mv\", \"_repo/data\", \".\"])\n",
    "            subprocess.run([\"mv\", \"_repo/scripts\", \".\"])\n",
    "            subprocess.run([\"rm\", \"-rf\", \"_repo\"])\n",
    "        else:\n",
    "            print(\"Warning: Data not found in cloned repo.\")\n",
    "    else:\n",
    "        print(\"Data directory found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f872f3",
   "metadata": {
    "id": "cell-93e2cb1e"
   },
   "source": [
    "# Embeddings API Example\n",
    "\n",
    "**What**: Generate and use text embeddings via a simulated API.\n",
    "\n",
    "**Why**: Many modern AI workflows offload heavy computation (like embedding generation) to specialized APIs.\n",
    "\n",
    "**How**:\n",
    "1. **Send text** to the embedding endpoint.\n",
    "2. **Receive vectors** in response.\n",
    "3. **Use vectors** for similarity calculations.\n",
    "\n",
    "**Key Concept**: **Embeddings** are dense numerical representations of text where similar meanings are close together in vector space.\n",
    "\n",
    "By the end of this notebook, you will have completed the listed steps and produced the outputs described in the success criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adec052b",
   "metadata": {
    "id": "cell-c48f1f97"
   },
   "source": [
    "### Success criteria\n",
    "- You generated embeddings for sample texts.\n",
    "- You computed similarity and inspected scores.\n",
    "- You executed a simple search over the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b75af",
   "metadata": {
    "id": "cell-ab95be5d"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd()\n",
    "for candidate in [repo_root, repo_root.parent, repo_root.parent.parent]:\n",
    "    if (candidate / \"api\" / \"python\" / \"client_embeddings.py\").exists():\n",
    "        sys.path.append(str(candidate))\n",
    "        break\n",
    "\n",
    "from api.python.client_embeddings import EmbeddingsClient\n",
    "\n",
    "texts = [\n",
    "    \"Synthetic research abstract about reproducibility.\",\n",
    "    \"Notes on experimental design and treatment arms.\",\n",
    "    \"Overview of responsible AI documentation practices.\",\n",
    "]\n",
    "\n",
    "client = EmbeddingsClient(max_features=32)\n",
    "embeddings = client.embed(texts)\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84633cd2",
   "metadata": {
    "id": "cell-f939d794"
   },
   "source": [
    "## Pairwise similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d0732",
   "metadata": {
    "id": "cell-50eff6ea"
   },
   "outputs": [],
   "source": [
    "similarity = client.similarity(texts)\n",
    "similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bb8bdb",
   "metadata": {
    "id": "cell-0a479846"
   },
   "source": [
    "### If you get stuck / What to try next\n",
    "\n",
    "If you get stuck: rerun installs and ensure sample texts are defined. What to try next: connect embeddings to retrieval workflows or try the text notebooks for qualitative checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d39e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIRE Micro Tutor Prompt + Feedback Cell\n",
    "from aire_llm_client import chat_completion\n",
    "\n",
    "def call_llm(prompt_text: str) -> str:\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': 'You are an AI helper responding concisely.'},\n",
    "        {'role': 'user', 'content': prompt_text},\n",
    "    ]\n",
    "    return chat_completion(messages)\n",
    "\n",
    "prompt_text = input('Enter the prompt you want to test: ').strip()\n",
    "ai_response = call_llm(prompt_text)\n",
    "evaluation = evaluate_prompt(prompt_text, learner_role)\n",
    "\n",
    "clarity = evaluation.get('clarity_score')\n",
    "context = evaluation.get('context_score')\n",
    "constraints = evaluation.get('constraints_score')\n",
    "evaluation_score = evaluation.get('evaluation_score')\n",
    "primary_weakness = evaluation.get('primary_weakness', '')\n",
    "recommended_resource_id = RESOURCE_MAP.get(primary_weakness) or RESOURCE_MAP.get('evaluation')\n",
    "\n",
    "log_event(\n",
    "    event_name='micro_tutor_evaluation',\n",
    "    user_id=learner_id or session_id,\n",
    "    metadata={\n",
    "        'resource_id': resource_id,\n",
    "        'learner_role': learner_role,\n",
    "        'clarity': clarity,\n",
    "        'context': context,\n",
    "        'constraints': constraints,\n",
    "        'evaluation_score': evaluation_score,\n",
    "        'primary_weakness': primary_weakness,\n",
    "    },\n",
    ")\n",
    "\n",
    "print('\\n--- AI Response ---')\n",
    "print(ai_response)\n",
    "print('\\n--- Feedback ---')\n",
    "print(evaluation.get('summary', 'No summary provided.'))\n",
    "print('Primary weakness:', primary_weakness or 'n/a')\n",
    "print('Strengths:', ', '.join(evaluation.get('strengths', [])) or 'n/a')\n",
    "print('Suggestions:', ', '.join(evaluation.get('suggestions', [])) or 'n/a')\n",
    "print('\\nRecommended resource:', recommended_resource_id or 'n/a')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
