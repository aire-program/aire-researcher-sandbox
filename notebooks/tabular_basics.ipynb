{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8adc1",
   "metadata": {
    "id": "cell-67ebd4ee"
   },
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "if \"google.colab\" in sys.modules:\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"pandas\", \"numpy\", \"scikit-learn\", \"requests\", \"pydantic\", \"jsonschema\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b5a97d",
   "metadata": {
    "id": "cell-9669ed90"
   },
   "source": [
    "# Clean Synthetic Experiment Records\n",
    "\n",
    "**What**: Load, validate, and clean synthetic experimental data.\n",
    "\n",
    "**Why**: Data quality is the foundation of reliable research. Identifying missing values, outliers, and inconsistencies early prevents errors in downstream analysis.\n",
    "\n",
    "**How**:\n",
    "1. **Load the dataset** into a pandas DataFrame.\n",
    "2. **Parse timestamps** to ensure correct temporal analysis.\n",
    "3. **Perform range checks** to identify invalid data points.\n",
    "\n",
    "**Key Concept**: **Data Validation** involves checking data against a set of rules (e.g., \"metrics must be between 0 and 100\") to ensure its logical consistency.\n",
    "\n",
    "By the end of this notebook, you will have completed the listed steps and produced the outputs described in the success criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ef4ff6",
   "metadata": {
    "id": "cell-9c20b43a"
   },
   "source": [
    "### Success criteria\n",
    "- You loaded experiment records.\n",
    "- You parsed timestamps and checked ranges.\n",
    "- You flagged or confirmed data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfdc8b",
   "metadata": {
    "id": "cell-0eca165a"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_data_dir() -> Path:\n",
    "    candidates = [Path.cwd() / \"data\", Path.cwd().parent / \"data\", Path.cwd().parent.parent / \"data\"]\n",
    "    for candidate in candidates:\n",
    "        if (candidate / \"sample_texts\" / \"articles_sample.csv\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"data directory not found. Run scripts/generate_synthetic_data.py.\")\n",
    "\n",
    "DATA_DIR = find_data_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2ecf12",
   "metadata": {
    "id": "cell-096e36e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "experiments = pd.read_csv(DATA_DIR / \"sample_tabular\" / \"experiments_sample.csv\")\n",
    "experiments[\"timestamp\"] = pd.to_datetime(experiments[\"timestamp\"])\n",
    "\n",
    "print(\"Dataset shape\", experiments.shape)\n",
    "print(\"Missing values\", experiments.isna().sum())\n",
    "experiments.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8e9fd",
   "metadata": {
    "id": "cell-3d2f85ab"
   },
   "source": [
    "## Basic range checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6552bf",
   "metadata": {
    "id": "cell-53c91437"
   },
   "outputs": [],
   "source": [
    "metric_out_of_range = (~experiments[\"metric_value\"].between(0, 100)).sum()\n",
    "print(f\"Records outside expected metric range: {metric_out_of_range}\")\n",
    "experiments.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc588b16",
   "metadata": {
    "id": "cell-4e5ab01f"
   },
   "source": [
    "### If you get stuck / What to try next\n\nIf you get stuck: ensure timestamps parse by rerunning the cleaning cell; confirm data generation. What to try next: create features in pipelines/tabular/feature_engineering.ipynb and visualize them in the tabular notebooks."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}