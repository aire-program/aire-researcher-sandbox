{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e4131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIRE Micro Tutor Identity Cell\n",
    "import datetime as dt\n",
    "learner_id = input('Enter your learner ID (email or handle): ').strip()\n",
    "learner_role = input('Enter your learner role (e.g., researcher, educator): ').strip()\n",
    "resource_id = 'notebook:text_classification'\n",
    "session_id = f\"{learner_id}-{dt.datetime.utcnow().isoformat()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a8e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIRE Micro Tutor Imports\n",
    "from prompt_tutor import evaluate_prompt\n",
    "from aire_telemetry import log_event\n",
    "from resources_map import RESOURCE_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345fc8b6",
   "metadata": {
    "id": "cell-ca79cc7a"
   },
   "outputs": [],
   "source": [
    "import sys, subprocess, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Colab Setup\n",
    "if \"google.colab\" in sys.modules:\n",
    "    print(\"Running in Google Colab. Installing dependencies...\")\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"pandas\", \"numpy\", \"scikit-learn\", \"requests\", \"pydantic\", \"jsonschema\", \"plotly\", \"tqdm\"])\n",
    "    \n",
    "    # Check for data\n",
    "    if not (Path.cwd() / \"data\").exists():\n",
    "        print(\"Data directory not found. Cloning repository...\")\n",
    "        subprocess.run([\"git\", \"clone\", \"https://github.com/aire-program/aire-researcher-sandbox.git\", \"_repo\"])\n",
    "        \n",
    "        # Move data and scripts to current directory\n",
    "        if (Path(\"_repo/data\").exists()):\n",
    "            print(\"Moving data and scripts...\")\n",
    "            subprocess.run([\"mv\", \"_repo/data\", \".\"])\n",
    "            subprocess.run([\"mv\", \"_repo/scripts\", \".\"])\n",
    "            subprocess.run([\"rm\", \"-rf\", \"_repo\"])\n",
    "        else:\n",
    "            print(\"Warning: Data not found in cloned repo.\")\n",
    "    else:\n",
    "        print(\"Data directory found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ca0479",
   "metadata": {
    "id": "cell-7618fdd5"
   },
   "source": [
    "# Cluster and Explore Topics\n",
    "\n",
    "**What**: Convert synthetic abstracts into numerical vectors (TF-IDF) and group them into thematic clusters using K-Means.\n",
    "\n",
    "**Why**: Clustering allows researchers to discover latent themes in large text corpora without manual labeling. It is a foundational technique for exploratory data analysis.\n",
    "\n",
    "**How**:\n",
    "1. **Vectorize text** using TF-IDF to represent documents as numbers.\n",
    "2. **Apply K-Means clustering** to group similar documents.\n",
    "3. **Inspect clusters** to interpret the discovered themes.\n",
    "\n",
    "**Key Concept**: **TF-IDF** (Term Frequency-Inverse Document Frequency) weighs words by how important they are to a document relative to the entire corpus. **K-Means** groups data points into *k* clusters by minimizing the distance to the cluster center.\n",
    "\n",
    "By the end of this notebook, you will have completed the listed steps and produced the outputs described in the success criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6369d49",
   "metadata": {
    "id": "cell-8bc33640"
   },
   "source": [
    "### Success criteria\n",
    "- You built a TF-IDF matrix and k-means clusters.\n",
    "- You inspected cluster counts.\n",
    "- You have cluster labels for each abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfdc8b",
   "metadata": {
    "id": "cell-4e09b7c3"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_data_dir() -> Path:\n",
    "    candidates = [Path.cwd() / \"data\", Path.cwd().parent / \"data\", Path.cwd().parent.parent / \"data\"]\n",
    "    for candidate in candidates:\n",
    "        if (candidate / \"sample_texts\" / \"articles_sample.csv\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"data directory not found. Run scripts/generate_synthetic_data.py.\")\n",
    "\n",
    "DATA_DIR = find_data_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c0df91",
   "metadata": {
    "id": "cell-834b6fea"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "articles = pd.read_csv(DATA_DIR / \"sample_texts\" / \"articles_sample.csv\")\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_matrix = vectorizer.fit_transform(articles[\"abstract\"].fillna(\"\"))\n",
    "\n",
    "model = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "articles[\"cluster\"] = model.fit_predict(tfidf_matrix)\n",
    "articles[[\"title\", \"cluster\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873a8615",
   "metadata": {
    "id": "cell-f1301183"
   },
   "source": [
    "## Inspect cluster composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb26be5",
   "metadata": {
    "id": "cell-0795b25b"
   },
   "outputs": [],
   "source": [
    "cluster_counts = articles.groupby(\"cluster\").size().reset_index(name=\"count\")\n",
    "cluster_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c8c38d",
   "metadata": {
    "id": "cell-cc06aa76"
   },
   "source": [
    "### If you get stuck / What to try next\n",
    "\n",
    "If you get stuck: confirm data generation and rerun the first cell to install dependencies. What to try next: evaluate summaries in pipelines/text/batch_summarization.ipynb or explore retrieval in pipelines/rag/build_index.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939731ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIRE Micro Tutor Prompt + Feedback Cell\n",
    "from aire_llm_client import chat_completion\n",
    "\n",
    "def call_llm(prompt_text: str) -> str:\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': 'You are an AI helper responding concisely.'},\n",
    "        {'role': 'user', 'content': prompt_text},\n",
    "    ]\n",
    "    return chat_completion(messages)\n",
    "\n",
    "prompt_text = input('Enter the prompt you want to test: ').strip()\n",
    "ai_response = call_llm(prompt_text)\n",
    "evaluation = evaluate_prompt(prompt_text, learner_role)\n",
    "\n",
    "clarity = evaluation.get('clarity_score')\n",
    "context = evaluation.get('context_score')\n",
    "constraints = evaluation.get('constraints_score')\n",
    "evaluation_score = evaluation.get('evaluation_score')\n",
    "primary_weakness = evaluation.get('primary_weakness', '')\n",
    "recommended_resource_id = RESOURCE_MAP.get(primary_weakness) or RESOURCE_MAP.get('evaluation')\n",
    "\n",
    "log_event(\n",
    "    event_name='micro_tutor_evaluation',\n",
    "    user_id=learner_id or session_id,\n",
    "    metadata={\n",
    "        'resource_id': resource_id,\n",
    "        'learner_role': learner_role,\n",
    "        'clarity': clarity,\n",
    "        'context': context,\n",
    "        'constraints': constraints,\n",
    "        'evaluation_score': evaluation_score,\n",
    "        'primary_weakness': primary_weakness,\n",
    "    },\n",
    ")\n",
    "\n",
    "print('\\n--- AI Response ---')\n",
    "print(ai_response)\n",
    "print('\\n--- Feedback ---')\n",
    "print(evaluation.get('summary', 'No summary provided.'))\n",
    "print('Primary weakness:', primary_weakness or 'n/a')\n",
    "print('Strengths:', ', '.join(evaluation.get('strengths', [])) or 'n/a')\n",
    "print('Suggestions:', ', '.join(evaluation.get('suggestions', [])) or 'n/a')\n",
    "print('\\nRecommended resource:', recommended_resource_id or 'n/a')"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
