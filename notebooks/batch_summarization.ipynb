{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee9f68",
   "metadata": {
    "id": "cell-37e85da0"
   },
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "if \"google.colab\" in sys.modules:\n",
    "    subprocess.run([\"pip\", \"install\", \"-q\", \"pandas\", \"numpy\", \"scikit-learn\", \"requests\", \"pydantic\", \"jsonschema\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153c65d7",
   "metadata": {
    "id": "cell-f1f7d790"
   },
   "source": [
    "# Batch Summarization (Heuristic)\n",
    "\n",
    "**What**: Generate extractive summaries of synthetic abstracts using heuristic methods.\n",
    "\n",
    "**Why**: Automated summarization enables researchers to rapidly triage large volumes of text. Heuristic methods provide a lightweight, offline baseline before applying more computationally expensive models.\n",
    "\n",
    "**How**:\n",
    "1. **Load text data**.\n",
    "2. **Apply a sentence selection heuristic** (e.g., first *n* sentences).\n",
    "3. **Compare** the summary to the original text.\n",
    "\n",
    "**Key Concept**: **Extractive Summarization** selects existing sentences from the text to create a summary, whereas **Abstractive Summarization** generates new sentences.\n",
    "\n",
    "By the end of this notebook, you will have completed the listed steps and produced the outputs described in the success criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b598ab7d",
   "metadata": {
    "id": "cell-315f917d"
   },
   "source": [
    "### Success criteria\n",
    "- You generated summaries for each abstract.\n",
    "- You compared original vs. summarized text.\n",
    "- You exported or viewed the summary table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfdc8b",
   "metadata": {
    "id": "cell-c8a67ca8"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_data_dir() -> Path:\n",
    "    candidates = [Path.cwd() / \"data\", Path.cwd().parent / \"data\", Path.cwd().parent.parent / \"data\"]\n",
    "    for candidate in candidates:\n",
    "        if (candidate / \"sample_texts\" / \"articles_sample.csv\").exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"data directory not found. Run scripts/generate_synthetic_data.py.\")\n",
    "\n",
    "DATA_DIR = find_data_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b3a68f",
   "metadata": {
    "id": "cell-da1b1a90"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "articles = pd.read_csv(DATA_DIR / \"sample_texts\" / \"articles_sample.csv\")\n",
    "\n",
    "\n",
    "def simple_summary(text: str, sentences: int = 2) -> str:\n",
    "    parts = [part.strip() for part in text.split('.') if part.strip()]\n",
    "    return '. '.join(parts[:sentences]) + ('.' if parts else '')\n",
    "\n",
    "articles[\"summary\"] = articles[\"abstract\"].apply(simple_summary)\n",
    "articles[[\"title\", \"summary\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0fa545",
   "metadata": {
    "id": "cell-da2d1da8"
   },
   "source": [
    "### If you get stuck / What to try next\n",
    "\n",
    "If you get stuck: check that the data files exist and rerun dependency installs. What to try next: feed summaries into retrieval by running pipelines/rag/build_index.ipynb and pipelines/rag/rag_query.ipynb."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}